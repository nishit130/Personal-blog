

[
  
  
    
    
  
    
    
  
    
    
  
    
    
  
    
    
  
    
    
  
    
    
      {
        "title": "Experience at KJSCE Hack 4.O",
        "excerpt": "In this blog, I will share my experience at KJSCE Hackathon 2019. first, let me explain what is a hackathon and if you already know than skip the next 5-6 lines.\n",
        "content": "\n\nIn this blog, I will share my experience at KJSCE Hackathon 2019. first, let me explain what is a hackathon and if you already know than skip the next 5-6 lines.\n\nHackathonâ€™s are of a various type depending on time for example 12hr, 24hr, 48hr or they can be different by themes like hardware and software hackathons. They are generally development based event where you have to create a working product which aimâ€™s to solve our day to day problem. Also it should be created within a time-bound given to you. It is a team-based event, generally a team of four. This much intro is enough for you to understand what is a hackathon, so lets start with my experience.\n\nIt was a 24hr Hackathon organized by KJSCE Codecell. My team name for the Hackathon was EUREKA, and the members were Nishit (myself) , Manan , Ali and Pathik. We were the only team from first year. As it was the first time we were participating in such event, so our goal was simple, we wanted to learn and connect with the people instead of racing for win.\n\nThe Coding Period began on 5th Oct at noon and our idea was to make a Hospital Management System website which was named as Hospipro. Then next task was to select a good tech stack to create Hospipro. We all agreed upon to use Django framework as our main tech stack. I was working on the Backend Development for the Website, it includes tasks like creating a login page for the doctor, patient list view, updates patient profile and creating different database models. Manan was working on the Frontend his task includes of web-design. Ali was developing the android version of our website using Kotlin language. Pathik Was given the task of creating a logoâ€™s, pptâ€™s etc required for final judging round.\n\n24hr seems to be lot of time but when we began with our work only then we realized its definelty not lot of time. Myself and my teammates were continuously coding for 24hrs straight day and night with just a nap of 2hrs. I enjoyed the mix of friendly as well as competetive enviroment of hackathon, and plan to participate in more such hackathons.\n\nOur product Hospipro included features like:\n\n\n  Secure Login Portal\n  Even when patients are unconscious we can scan the generated QR code from their IDs\n  The ability for doctors to update patients profile with their profile picture\n  The doctor can easily handle information of their patients in just one click\n  Patients can also have access to their medical history\n\n\nScreenshots\n\n\n\nI noticed that most of the teams were using new and easy to build tech stack like Flask, nodejs etc for the backend, and during the judging round. I would like to suggest that, if you are planning to participate in your first hackathon then do make some pre-preparation regarding the idea and how you are going to implement it.\n\nSource Code of HospiproÂ  github\n\n\nImages taken during Hackathon\n\n\n\n",
        "url": "/kjsce-hack/2019/10/08/experience-at-kjsce-hack.html"
      },
    
      {
        "title": "Beginning my GSoC Journey",
        "excerpt": "This is going to be an introductory blog where I will talk about the project on which Iâ€™ll be working this summer in GNOME Foundation.\n",
        "content": "This was my reaction after finding out that I was selected for GSoC :)\n\n\n\nsource: Giphy\n\n\nI am starting a new blog series, for covering my GSoCâ€™21 journey with GNOME Foundation. This is going to be an introductory blog where I will talk about the project on which Iâ€™ll be working this summer. Before we get started let me introduce myself to the folks reading from the GNOME planet. I am Nishit Patel, an undergraduate Computer Engineering student from India.\n\nI began my pre GSoC journey back in November 2020 when I opened my first MR in tracker project. It was a small bug fix in the README.md file which I came across while setting up my local environment. Later, I began keeping a watch on the #tracker IRC and used to ask maintainers for help whenever I was stuck at something. Maintainers were very helpful and polite with their prompt replies even if I was asking some stupid question that was already addressed somewhere in the documentation. One thing that I noticed is it is better to first google, and check the docs before asking the question as it saves the maintainers precious time, and you also get to learn something new in the process.\n\nProject details\n\nI will be working on the Tracker-miner project which is an indexer, and also used for extracting the metadata from different file formats. Tracker currently doesnâ€™t store the creation time in the database as it was historically not tracked on UNIX file systems, and itâ€™s not part of POSIX specification. However, Since kernel version 4.11 the new statx system call provides the file creation timestamp. Based on this, the project aims to provide the support of storing file creation time in the tracker database and later, provide the feature of searching by creation time in Nautilus.\n\nI will be writing short posts as and when I get time in between so\n\n\n\nsource: Giphy\n\n",
        "url": "/gsoc'21/2021/05/31/start-of-gsoc-jouney.html"
      },
    
      {
        "title": "GSoC Project update part I",
        "excerpt": "Weekly update of GSoCâ€™21 project. Includeâ€™s work done on week 1, 2 and 3.\n",
        "content": "This is a weekly update of my GSoC project.\n\nWeek 1\n\nFollowing the proposed schedule, I began working on the first milestone, i.e Adding support for creation time in tracker-miners. While building the tracker-miner I discovered crashes in the indexer. After taking some help from mentors and debugging,\nIt was found that a double-free bug in the indexer was causing the crash. As the piece of code was unused, it went unnoticed.\n\nMerge Requests: !440\n\nWeek 2\n\nDuring 2nd week, Most of the time was spent writing code. I was also working on resolving threads in the merge requests which were opened before GSoC.\n\nMerge Requests: !327\n\nWeek 3\n\nOpend Draft MR for the first milestone, and fixed some of the coverity warnings which were introduced after merging !327.\n\nMerge Requests:\n!336,\n !340\n",
        "url": "/gsoc'21/2021/06/29/gsoc-project-update.html"
      },
    
      {
        "title": "GSoC Project update part II",
        "excerpt": "Weekly update of GSoCâ€™21 project. Includeâ€™s work done on week 4, 5, 6 and 7.\n",
        "content": "For the previous weekâ€™s update check out my last post.\n\nWeek 4\n\nWhile reading the documentation, I came across a bug that was leading to broken links. After some debugging and testing, I was able to fix the bug. It was due to a missing configuration in the documentation engine.\n\nIssues: #317\n\nMerge Requests: !446\n\nWeek 5\n\nResolved all the threads, and marked the MR ready for merge. After few more changes MR was merged, and with this one out of two project goal was achieved.\n\nIssue: #158\n\nMerge Requests: !340\n\nWeek 6\n\nI began working towards my second milestone. Cloned the nautilus repository and spent few days understanding the codebase.  I was also working on my GUADEC presentation (hopefully will write a separate blog for it :-).\n\nWeek 7\n\nOpened MR for search by creation time in nautilus, and while writing tests for nautilus discovered a bug and fixed it.\n\nIssues: #1933\n\nMerge Requests: !693, !697\n",
        "url": "/gsoc'21/2021/08/02/gsoc-project-update-part-ii.html"
      },
    
      {
        "title": "GSoC final submission",
        "excerpt": "It has been a great journey working on the Tracker project. In the past 10 weeks I got to learn a lot about the project and its architecture â€¦\n",
        "content": "It has been a great journey working on the Tracker project. In the past 10 weeks, I got to learn a lot about the project and its architecture. This is the final submission of the project. For the weekly updates, check out my previous posts here.\n\nProposed project goals\n\n:heavy_check_mark: Add support of file-creation time in Tracker-miners.\n:heavy_check_mark: Add feature of search by file-creation time in Nautilus.\n:heavy_check_mark: Improve nautilus-search engine tests suite.\n\nContributions\n\nMajor contributions were done in Tracker-miners and Nautilus projects during the coding period.\n\nAdd support of file-creation time in Tracker-miners\n\nThis was the major primary goal of the project. After adding this feature, Tracker-miners now supports storing and querying file-creation time. While working on this feature, I also discovered and eventually fixed a double free bug in the indexer.\n\nPull Requests \n!440 (Merged), \n!340 (Merged)\n\nIssues \n#158 (Closed)\n\nAdd feature of search by file-creation time in Nautilus\n\nThis feature depends on previous work done in Tracker-miners. After adding this feature, Nautilus now supports searching files by file-creation time.\n\nPull Requests \n!693 (Merged)\n\nIssues \n#1761 (Closed)\n\nImprove nautilus-search engine tests suite.\n\nInitially, there were only two proposed goals. After having chat with the mentors, we decided to extend the project by adding one more goal to improve the nautilus-search engine test suite. While writing tests I found a bug in the nautilus-tracker-search-engine due to improper date-time format. After fixing this bug, I added tests for searching files by modification and access time in all search engines.\n\nPull Requests \n!697 (Merged), \n!701 (Open under review)\n\nIssues \n#1933 (Closed)\n\nOther miscellaneous contributions\n\nThis work was done during the GSoC period but is not part of the project goals.\n\nPull Requests\n!446 (Merged), \n!336 (Merged)\n\nIssues \n#317 (Closed)\n\nFuture Goals\n\nResolve any unresolved threads in the open Merge Requests. Write more tests for search by file creation time in Nautilus. Continue contributing to the projects.\n\nClosing thoughts\n\nIt was an amazing experience working in GNOME Community. I would like to thank my mentors Carlos and Sam for giving constructive suggestions and guiding me through the program, also thanks to AntÃ³nio for quick code reviews. I enjoyed attending and giving a talk at GUADEC conference and got to learn about different projects in the GNOME Circle. Looking forward to continue contributing to GNOME projects.\n\nQuick links\n\n\nAll Merge Requests\nAll Issues\nWeekly update's\nMy Gitlab Account\nGUADEC Talk\n\n\n\n\n\n\n",
        "url": "/gsoc'21/2021/08/21/gsoc-final-submission.html"
      },
    
      {
        "title": "How to create custom signed URLs",
        "excerpt": "In todayâ€™s cloud-based world, secure and efficient access to private resources stored on cloud platforms is crucial. One of the ways to provide secure access to these resources is by using Signed URLsâ€¦.\n",
        "content": "\n\nListen to blog in podcast format ðŸ‘‡\n\n../../../../assets/custom_url_podcast.mp3\n\nIn todayâ€™s cloud-based world, secure and efficient access to private resources stored on cloud platforms is crucial. One of the ways to provide secure access to these resources is by using Signed URLs. Signed URLs allow users to access private objects on cloud platforms like Amazon Web Services (AWS) S3 and Google Cloud Storage (GCS).\n\nA signed URL is a special type of URL that includes a signature, or token, that verifies the identity of the user or application making the request to access a specific resource, such as an object stored in GCS/S3 bucket. This token allows the server to confirm that the user or application has the necessary permissions to access the resource and prevent unauthorized access.\n\nMajor cloud platforms like AWS and GCP provide functionality of signed URL but they have a limitation on the expiry of the URL. We can set maximum expiry time to only 7 days. To overcome this constraints of expiry In this blog you will learn how to create your own custom signed urlâ€™s for your usecase.\n\nSo, why should you care about custom signed URLs? Consider these scenarios:\n\n\n  You need to provide limited access to private resources for a temporary period, without granting permanent rights.\n  You wish to let users download files without going through tedious multiple authentication.\n  You intend to generate time-limited URLs, specifically for sharing resources based on your productâ€™s RBAC.\n\n\nImagine owning an e-learning platform where students can access various course materials, from lecture videos and presentation slides to supplementary documents. To accommodate their learning journey, you want to offer them access for an extended period, perhaps the entire semester. Hereâ€™s where you encounter a roadblock: the 7-day expiry limit imposed by AWS and GCS. To bypass this hurdle, you need a custom implementation of the signed URL feature.\n\nThis is how high level architecture is going to look like.\n\n\n\nUsers will send a Get request to your backend API server through a signed URL. The response to this request will be determined by the parameters in the signed URL. To qualify as a signed URL, the custom signed URL should adhere to the following three principles:\n\n\n  Time-Limited Access: The URL is a temporary passport, bearing an expiration time or duration that restricts access to a specific timeframe.\n  Controlled Access Permissions: The URL must carry the necessary access permissions, much like a VIP pass for a specific event, granting entry only for the requested operation.\n  Secure Authentication and Authorization: The URL must ensure that only those bearing proper credentials can access the resource.\n\n\nURL Structure\n\nHereâ€™s a blueprint of your signed URL\n\n\n\nThe token parameter serves as the HMAC (Hashed Message Authentication Code), a cryptographic signature formed using a secret key and the other URL parameters. It guarantees the integrity and authenticity of the signed URL, making any alterations in the parameters futile by invalidating the URL. \nexpiry parameter helps in defining the expiry of the url while generating it. \nuser_id parameter or any other unique identifier can be used, will help in verifying that user has authorization to access the content requested by the singed url.\nHere is an illustrative python code snippet for generating signed URLs:\n\n\nBASE_URL = \"http://api-server.com/\"\n\ndef generate_signed_url(user_id, object_name, expiry):\n    try:\n\t# Create new secret-key or user existing from db\n        encrypted_secret = get_signed_url_secret_from_id(user_id)\n\n        if encrypted_secret is None:\n            encrypted_secret = generate_secret_key(user_id)\n\t\t\t\t\n        # decrypt secret key\n        secret = decrypt_with_prefix_iv(encrypted_secret)\n\t\t\t\t\n\t# add expiry of 91 days\n        expiry = datetime.datetime.now() + datetime.timedelta(days=91)\n        expiry_timestamp = int(expiry.timestamp() * 1000)\n\n        signed_url = f'{BASE_URL}/endpoint?user_id={str(user_id)}&amp;expiry={str(expiry_timestamp)}&amp;object={object_name}'\n\n        data = {\n\t        \"user_id\": str(user_id),\n\t\t\"object_name\": object_name,\n\t        \"expiry\": str(expiry)\n\t}\n        hmac_code = generate_code(data, secret)\n        signed_url += \"&amp;token=\" + hmac_code\n        return signed_url\n\n    except Exception as e:\n        pass # Error handling\n        return None\n\n\nBackend API\n\nLetâ€™s define the Backend logic for serving the requested content whenever a Get request is made to our https://api-server.com/endpoint . Here is the pseudo python code for implementation of the api.\n\n@app.get(\"/endpoint\")\ndef get_course_ppt(user_id: UUID, object_name: str, expiry: int, token: str) -&gt; Response:\n    # Check if URL is expired\n    if expiry &lt; int(datetime.now().timestamp() * 1000):\n        return Response(status=400, entity=\"URL is expired\")\n\n    # fetch secret-key for user\n    encrypted_secret = userUtil.get_signed_url_secret_from_id(user_id)\n\t\t\n    # decrypt encrypted secret-key stored in db\n    secret = AESUtil.decrypt_with_prefix_iv(encrypted_secret)\n\n    data = {\n        \"user_id\": str(user_id),\n\t\"object_name\": object_name,\n        \"expiry\": str(expiry)\n    }\n\t\t\n    # check if caclulated hmac is same as token\n    if HmacUtil.matches(data, secret, token): \n        # Fetch object from GCS/S3       \n        ppt = GoogleStorageUtils.get_file_as_is(bucket_name, object_name)\n\n        return Response(status=200, entity=ppt,\n                        media_type=MediaType.APPLICATION_OCTET_STREAM,\n                        headers={HttpHeaders.CONTENT_DISPOSITION: 'attachment;\n                                 filename=\"' + object_name + '\"'\n                        })\n    else:\n        return Response(status=401, entity=\"Invalid URL\")\n\n    # Exception handling\n    except Exception as e:\n        logger.error(e)\n        return Response(status=500, entity=\"Some error occurred\")\n\n\nWe check if calculated value of HMAC matches the token to make sure that the url parameters are not tampered by the third party.\n\nConclusion\n\nConcluding, signed URLs are your trusted allies in securing access to your cloud-hosted private resources. However, the 7-day expiry limit can sometimes be a hindrance. Creating custom signed URLs, honoring the principles of time-limited access, controlled access permissions, and secure authentication and authorization, is a savvy way to circumvent this challenge. This strategy empowers you to provide temporary access to your resources while ensuring optimal security and control.\n\n\n\n\n\n",
        "url": "/tutorials/2023/06/01/custom-signed-urls.html"
      },
    
  
    
    
  
  
  
  {
    "title": "Categories",
    "excerpt": "Category index\n",
    "content": "\n",
    "url": "/categories.html"
  }
  
]

